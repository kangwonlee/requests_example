{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNre8utNmG0M9PgbkvVHpgx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kangwonlee/requests_example/blob/main/requests_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* https://github.com/kangwonlee/requests_example\n",
        "* https://requests.readthedocs.io/en/latest/\n",
        "* hyper text transfer protocol &rarr; HTTP"
      ],
      "metadata": {
        "id": "nI_XGkrgCuKP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cN_atBDdCcdr"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://comic.naver.com/webtoon/weekday\"\n",
        "r = requests.get(url)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r.ok\n",
        "\n"
      ],
      "metadata": {
        "id": "xtgf1vIGDK62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "bs4 : Beautiful Soup 4"
      ],
      "metadata": {
        "id": "5ili6iz4Dre4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4\n",
        "soup = bs4.BeautifulSoup(r.text)\n",
        "\n"
      ],
      "metadata": {
        "id": "g20vZCYlDW5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 파일 이름 찾기"
      ],
      "metadata": {
        "id": "Hdo0VNkKUNL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first = soup.find_all(\"img\")[0]\n",
        "first"
      ],
      "metadata": {
        "id": "YYSh6yMCPkwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_url = first.get(\"src\")\n",
        "img_url"
      ],
      "metadata": {
        "id": "OcA5OKSOQjSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.parse as up\n",
        "parsed = up.urlparse(img_url)\n",
        "parsed"
      ],
      "metadata": {
        "id": "ltv1gFlRQy7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parsed.path.split('/')"
      ],
      "metadata": {
        "id": "_-IbngQqQ-Jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fname = parsed.path.split('/')[-1]\n",
        "fname"
      ],
      "metadata": {
        "id": "T3oUS3gZRG_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fname.endswith(\".jpg\")"
      ],
      "metadata": {
        "id": "h0QMw3LBRMdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## for 반복문으로 받기"
      ],
      "metadata": {
        "id": "c-jdykzoCUOU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "urllib 대신 requests 로 받도록 바꾸어 보기 바랍니다"
      ],
      "metadata": {
        "id": "Xu34u4lHJaRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "import urllib.parse as up\n",
        "\n",
        "for img_tag in soup.find_all('img'):\n",
        "  img_url = img_tag.get('src')\n",
        "\n",
        "  parsed = up.urlparse(img_url)\n",
        "  fname = parsed.path.split('/')[-1]\n",
        "\n",
        "  if fname.endswith(\".jpg\"):\n",
        "\n",
        "    print(img_url)\n",
        "    urllib.request.urlretrieve(img_url, fname)\n",
        "\n"
      ],
      "metadata": {
        "id": "_agAC2_HED8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `jpg` 파일을 `download_this.zip` 파일로 압축<br>\n",
        "참고문헌 : <br>\n",
        "* https://stackoverflow.com/questions/71251353/how-to-create-a-zip-archive-containing-multiple-files-and-subfolders-in-memory\n"
      ],
      "metadata": {
        "id": "ickpkW_GR7Ys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "# https://stackoverflow.com/questions/71251353/how-to-create-a-zip-archive-containing-multiple-files-and-subfolders-in-memory\n",
        "\n",
        "with open(\"download_this.zip\", 'wb') as fo:\n",
        "  with zipfile.ZipFile(fo, 'w') as zf:\n",
        "    for fname in os.listdir():\n",
        "      if fname.endswith('.jpg'):\n",
        "        zf.write(fname, fname)\n",
        "        os.remove(fname)\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "MhUJN--PNdpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UTtN_zSEOr-c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}